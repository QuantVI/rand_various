{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7f68812",
   "metadata": {},
   "source": [
    "# Single-file compilation of the original author's coding efforts for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32895dd3",
   "metadata": {},
   "source": [
    "Attempting to use a tooltip.\n",
    "\n",
    "This test will show how tooltips redner in Jupyter itself, and in Github once this notebook is uploaded.\n",
    "\n",
    "*Example*: <span title=\"Your tooltip text here\">Hover over me</span>\n",
    "\n",
    "\n",
    "<u>Tooltips of increasing length</u>\n",
    "* We will re-use this line: \"Single-file compilation of original author's coding efforts for the model\"\n",
    "* it is 10-words total.\n",
    "\n",
    "---\n",
    "* After testing, using chained repetitions of the 10-word line above, we fit $136$ words into 1 tooltip.\n",
    "* This amounted to $1018$ characters as one line (no newline etc) **with** spaces\n",
    "* This amounted to $883$ characters as onel line (no newlines etc) ***without** considering spaces\n",
    "\n",
    "\n",
    "10 words: <span title=\"Single-file compilation of original author's coding efforts for the model\">Hover over me</span>\n",
    "\n",
    "100 words: <span title=\"Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model[100]\">Hover over me</span>\n",
    "\n",
    "200 words: <span title=\"Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model[100] Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model Single-file compilation of original author's coding efforts for the model[100]\">Hover over me</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d4c896",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f34e43d",
   "metadata": {},
   "source": [
    "# I - PD_IFRS.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e41731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6cf02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc4e141",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7244877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8816a437",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0cdafe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3abfb868",
   "metadata": {},
   "source": [
    "# II - PD_Model.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899e1c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad493b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8004512",
   "metadata": {},
   "source": [
    "# III - Credit Risk.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e0fc22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7639fcef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123c6b13",
   "metadata": {},
   "source": [
    "# IV - Credit Risk 2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a38ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f37f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38f83985",
   "metadata": {},
   "source": [
    "# V - Dependent Var Code.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df6ab72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default variable distribution:\n",
      "0    237722\n",
      "1         5\n",
      "Name: default, dtype: int64\n",
      "\n",
      "Loan status distribution:\n",
      "Fully Paid     10\n",
      "Charged Off     5\n",
      "Current         2\n",
      "Name: loan_status, dtype: int64\n",
      "Fully Paid     10\n",
      "Charged Off     5\n",
      "Current         2\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# - - - - Full code - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "import pandas as pd # Import pandas for daa handling\n",
    "\n",
    "# Set your file path to the CSV file on your Desktop\n",
    "# My edit: --> We use the RAW in Github instead\n",
    "file_path = \"https://raw.githubusercontent.com/QuantVI/\"\n",
    "file_path += \"rand_various/refs/heads/main/\"\n",
    "file_path += \"Python_PD_LGD_EAD_Modeling/2_original/loan_data.csv\"\n",
    "\n",
    "try:\n",
    "    # Load the dataset from the specified path\n",
    "    # My edit --> due to detection of mixed datatypes many columns,\n",
    "      # we need to turn OFF the low_memory setting.\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    # Create a new binary column 'default' : 1 if risk status, else 0\n",
    "    # My edit --> create status list first\n",
    "    bad_statuses = [\"Charged Off\",\n",
    "                    \"Default\",\n",
    "                    \"Late (31-120 days)\",\n",
    "                    \"Late (16-30 days)\"]\n",
    "    df['default'] = df['loan_status'].apply(\n",
    "        lambda x: 1 if x in bad_statuses else 0\n",
    "    )\n",
    "    \n",
    "    # Print the count of defaults (1) vs non-defaults (0)\n",
    "    print(\"Default variable distribution:\")\n",
    "    print(df[\"default\"].value_counts())\n",
    "    \n",
    "    # Print how many loans fall into each original loan_status category\n",
    "    print(\"\\nLoan status distribution:\")\n",
    "    print(df[\"loan_status\"].value_counts())\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # Message to print if the file path is incorrect or file is missing\n",
    "    print(\"File not found. Please check the file path.\")\n",
    "\n",
    "except Exception as e:\n",
    "    # Catch and print any other unexpected errors\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "print(df[\"loan_status\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d904ef7",
   "metadata": {},
   "source": [
    "$\\uparrow~\\uparrow~\\uparrow$  \n",
    "**My note** :\n",
    "The results above show that the data is extremely skewed. We have hardly an actual defaults, and no records that are even delinquent. This means very few direct examples of what a defaulter resembles, to learn from.\n",
    "\n",
    "<font color=magenta>We actually have a major issue with the loan_status column being <b>NaN</b> for 237 710 of 237 727 total values</font>. Its $99.992\\%$ blank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317266c",
   "metadata": {},
   "source": [
    "The main problem is that the `loan_data.csv` in the original repo was moslty blank and likely not what was intended ot be there. We need a new file for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98c61ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'id', 'member_id', 'loan_amnt', 'funded_amnt',\n",
      "       'funded_amnt_inv', 'term', 'int_rate', 'installment', 'grade',\n",
      "       'sub_grade', 'emp_title', 'emp_length', 'home_ownership', 'annual_inc',\n",
      "       'verification_status', 'issue_d', 'loan_status', 'pymnt_plan', 'url',\n",
      "       'desc', 'purpose', 'title', 'zip_code', 'addr_state', 'dti',\n",
      "       'delinq_2yrs', 'earliest_cr_line', 'inq_last_6mths',\n",
      "       'mths_since_last_delinq', 'mths_since_last_record', 'open_acc',\n",
      "       'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n",
      "       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n",
      "       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n",
      "       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n",
      "       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n",
      "       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n",
      "       'policy_code', 'application_type', 'annual_inc_joint', 'dti_joint',\n",
      "       'verification_status_joint', 'acc_now_delinq', 'tot_coll_amt',\n",
      "       'tot_cur_bal', 'open_acc_6m', 'open_il_6m', 'open_il_12m',\n",
      "       'open_il_24m', 'mths_since_rcnt_il', 'total_bal_il', 'il_util',\n",
      "       'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util',\n",
      "       'total_rev_hi_lim', 'inq_fi', 'total_cu_tl', 'inq_last_12m'],\n",
      "      dtype='object')\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5ec3dc",
   "metadata": {},
   "source": [
    "$\\uparrow~\\uparrow~\\uparrow$  \n",
    "We have $75$ total columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf89eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce2e73f4",
   "metadata": {},
   "source": [
    "# VI - Split_Train_Test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "06eb84f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# My edit to facilitate data import\n",
    "import pandas as pd\n",
    "fpath = \"https://raw.githubusercontent.com/QuantVI/rand_various/refs/\"\n",
    "fpath += \"heads/main/Python_PD_LGD_EAD_Modeling/2_original/loan_data.csv\"\n",
    "\n",
    "df = pd.read_csv(fpath, low_memory=False)\n",
    "\n",
    "PRIOR_WARNING = \"\"\"C:\\etc...\\interactiveshell.py:3444: DtypeWarning: \n",
    "Columns (6,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,27,36,46,48,49,53) \n",
    "have mixed types.Specify dtype option on import or set low_memory=False.\n",
    "  exec(code_obj, self.user_global_ns, self.user_ns)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c705d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features shape: (13, 75)\n",
      "Training labels shape:\t (13,)\n",
      "Test Features shape:\t (4, 75)\n",
      "Test labels shape:\t (4,)\n"
     ]
    }
   ],
   "source": [
    "# - - - - Full code - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "\n",
    "# Import the function to split data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Drop rows where the target column 'loan_status' is missing\n",
    "# Missing target values can't be used for training or testing\n",
    "df = df.dropna(subset=[\"loan_status\"])\n",
    "\n",
    "# Separate the features (input variables) \n",
    "  # from the target (label to predict)\n",
    "# X will contain al columns except 'loan_status'\n",
    "# y will contain only the 'loan_status' column\n",
    "X = df.drop(columns=\"loan_status\")\n",
    "y = df[\"loan_status\"]\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "# test_size=0.2 means 20% of the data goes to the test set and\n",
    "  # 80% to the training set.\n",
    "# random_state=42 ensures the split is reproducible for each run.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.2,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# Print the shape (dimensions) of each dataset to confirm the split\n",
    "print(\"Training features shape:\", X_train.shape) # X_train rows, cols\n",
    "print(\"Training labels shape:\\t\", y_train.shape)   # y_train rows, cols\n",
    "print(\"Test Features shape:\\t\", X_test.shape)     # X_test rows, cols\n",
    "print(\"Test labels shape:\\t\", y_test.shape)       # y_test rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed236bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN            237710\n",
       "Fully Paid         10\n",
       "Charged Off         5\n",
       "Current             2\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_status.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d116a6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Fully Paid\n",
       "1     Charged Off\n",
       "2      Fully Paid\n",
       "3      Fully Paid\n",
       "4         Current\n",
       "5      Fully Paid\n",
       "6         Current\n",
       "7      Fully Paid\n",
       "8     Charged Off\n",
       "9     Charged Off\n",
       "10     Fully Paid\n",
       "11     Fully Paid\n",
       "12    Charged Off\n",
       "13     Fully Paid\n",
       "14    Charged Off\n",
       "15     Fully Paid\n",
       "16     Fully Paid\n",
       "Name: loan_status, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"loan_status\"][~df[\"loan_status\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0eb2189",
   "metadata": {},
   "source": [
    "$\\uparrow~\\uparrow~\\uparrow$  \n",
    "**My note** : Unfortunately, `loan_status` is **NaN** 99.99% of the time. There are onyl 17 rows with a populated `loan_status`. This means, the usage of `df = df.dropna(subset=[\"loan_status\"])` guts our dataset. We'll have to do something else if we want anything useful to model.\n",
    "\n",
    "Using `df.loan_status.value_counts(dropna=False)` before any drops, we understand the true issue\n",
    "\n",
    "```\n",
    "NaN            237710\n",
    "Fully Paid         10\n",
    "Charged Off         5\n",
    "Current             2\n",
    "Name: loan_status, dtype: int64\n",
    "```\n",
    "\n",
    "The total data set is 237 727 rows, but only 17 of the **loan_status** rows have a status.\n",
    "\n",
    "<font color=blue face=Verdana>More than likely the original file was split ro somehow truncated, and this small subset was saved from an Excel spreadsheet, which forced 237K rows even though only 18 (header included) were populated</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a3adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
